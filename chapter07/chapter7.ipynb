{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7. Random Walk Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all states\n",
    "N_STATES = 19\n",
    "\n",
    "# discount\n",
    "GAMMA = 1\n",
    "\n",
    "# all states but terminal states\n",
    "STATES = np.arange(1, N_STATES + 1)\n",
    "\n",
    "# start from the middle state\n",
    "START_STATE = 10\n",
    "\n",
    "# two terminal states\n",
    "# an action leading to the left terminal state has reward -1\n",
    "# an action leading to the right terminal state has reward 1\n",
    "END_STATES = [0, N_STATES + 1]\n",
    "\n",
    "# true state value from bellman equation\n",
    "TRUE_VALUE = np.arange(-20, 22, 2) / 20.0\n",
    "TRUE_VALUE[0] = TRUE_VALUE[-1] = 0\n",
    "\n",
    "# n-steps TD method\n",
    "# @value: values for each state, will be updated\n",
    "# @n: # of steps\n",
    "# @alpha: # step size\n",
    "def temporal_difference(value, n, alpha):\n",
    "    # initial starting state\n",
    "    state = START_STATE\n",
    "\n",
    "    # arrays to store states and rewards for an episode\n",
    "    # space isn't a major consideration, so I didn't use the mod trick\n",
    "    states = [state]\n",
    "    rewards = [0]\n",
    "\n",
    "    # track the time\n",
    "    time = 0\n",
    "\n",
    "    # the length of this episode\n",
    "    T = float('inf')\n",
    "    while True:\n",
    "        # go to next time step\n",
    "        time += 1\n",
    "\n",
    "        if time < T:\n",
    "            # choose an action randomly\n",
    "            if np.random.binomial(1, 0.5) == 1:\n",
    "                next_state = state + 1\n",
    "            else:\n",
    "                next_state = state - 1\n",
    "\n",
    "            if next_state == 0:\n",
    "                reward = -1\n",
    "            elif next_state in [20, 3]:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = 0\n",
    "\n",
    "            # store new state and new reward\n",
    "            states.append(next_state)\n",
    "            rewards.append(reward)\n",
    "\n",
    "            if next_state in END_STATES:\n",
    "                T = time\n",
    "\n",
    "        # get the time of the state to update\n",
    "        update_time = time - n\n",
    "        if update_time >= 0:\n",
    "            returns = 0.0\n",
    "            # calculate corresponding rewards\n",
    "            for t in range(update_time + 1, min(T, update_time + n) + 1):\n",
    "                returns += pow(GAMMA, t - update_time - 1) * rewards[t]\n",
    "            # add state value to the return\n",
    "            if update_time + n <= T:\n",
    "                returns += pow(GAMMA, n) * value[states[(update_time + n)]]\n",
    "            state_to_update = states[update_time]\n",
    "            # update the state value\n",
    "            if not state_to_update in END_STATES:\n",
    "                value[state_to_update] += alpha * (returns - value[state_to_update])\n",
    "        if update_time == T - 1:\n",
    "            break\n",
    "        state = next_state\n",
    "\n",
    "    # all possible steps\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.power(2, np.arange(0, 10))\n",
    "\n",
    "# all possible alphas\n",
    "alphas = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# each run has 10 episodes\n",
    "episodes = 10\n",
    "\n",
    "# perform 100 independent runs\n",
    "runs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:38<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# track the errors for each (step, alpha) combination\n",
    "errors = np.zeros((len(steps), len(alphas)))\n",
    "for run in tqdm(range(0, runs)):\n",
    "    for step_ind, step in enumerate(steps):\n",
    "        for alpha_ind, alpha in enumerate(alphas):\n",
    "            # print('run:', run, 'step:', step, 'alpha:', alpha)\n",
    "            value = np.zeros(N_STATES + 2)\n",
    "            for ep in range(0, episodes):\n",
    "                temporal_difference(value, step, alpha)\n",
    "                # calculate the RMS error\n",
    "                errors[step_ind, alpha_ind] += np.sqrt(np.sum(np.power(value - TRUE_VALUE, 2)) / N_STATES)\n",
    "# take average\n",
    "errors /= episodes * runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1_/nbsl741j2dn4q7znr51t4ld80000gp/T/ipykernel_76100/3959769181.py:6: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(steps)):\n",
    "    plt.plot(alphas, errors[i, :], label='n = %d' % (steps[i]))\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('RMS error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('./figure_7_2.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
